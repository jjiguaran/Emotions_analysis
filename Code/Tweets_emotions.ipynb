{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sem_eval_2018_task_1 (/home/juanjo/.cache/huggingface/datasets/sem_eval_2018_task_1/subtask5.spanish/1.1.0/a7c0de8b805f1988b118882fb289ccfbbeb9085c7820b6f046b5887e234af182)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c56d962db44e0f8bb2ce0d084c79bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('sem_eval_2018_task_1', 'subtask5.spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: emo_event/es\n",
      "Found cached dataset emo_event (/home/juanjo/.cache/huggingface/datasets/fmplaza___emo_event/es/1.1.0/05d5c93b8773e3d90b52effb7132b04cd8b2ccea8d4a0750989ec3aaeb59cad4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bae356192b4017a948144956127d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset2 = load_dataset('fmplaza/EmoEvent', use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import os\n",
    "import unidecode\n",
    "#import datetime\n",
    "from datetime import timedelta, datetime \n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token = \"AAAAAAAAAAAAAAAAAAAAAKKEcwEAAAAA1VgzT5upnu%2B5POQ3dbdUx0%2B5vfA%3DdslAW6ut31gZhQD9SjNKJ4scCFd8bHgbevp8eGcJprbd2LTrGf\", wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_df = pd.read_csv('../Data/corpus_marcado6emociones.txt', sep=' ',skiprows=19, header=None, names = ['id','Emocion']).apply(lambda s:s.str.replace(\"'\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 313 seconds.\n"
     ]
    }
   ],
   "source": [
    "inicio = 0\n",
    "for i in list(range(100,len(ids_df),100)) + [len(ids_df)]:\n",
    "    ids_list = list(ids_df['id'][inicio:i])\n",
    "    emocion_list = ids_df['Emocion'][inicio:i]\n",
    "    data = client.get_tweets(ids = ids_list).data\n",
    "    if data != None:\n",
    "        text_list = [j.text for j in data ]\n",
    "        ids_list = pd.Series([j.id for j in data ]).astype(str)\n",
    "        emocion_list = ids_df[inicio:i][ids_df['id'][inicio:i].isin(ids_list)][inicio:i]['Emocion'].reset_index(drop = True)\n",
    "    inicio = i\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_list = list(ids_df['id'][0:100])\n",
    "emocion_list = ids_df['Emocion'][0:100]\n",
    "data = client.get_tweets(ids = ids_list).data\n",
    "text_list = [i.text for i in data ]\n",
    "ids_list = pd.Series([i.id for i in data ]).astype(str)\n",
    "emocion_list = ids_df[0:100][ids_df['id'][0:100].isin(ids_list)][0:100]['Emocion'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emocion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465049714141200384</td>\n",
       "      <td>Buuenoos diiias ya estoy con mii pekeñaa!! Y c...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>468241881428951041</td>\n",
       "      <td>Nuevos proyectos, nuevas metas, una nueva sema...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>469580509895729153</td>\n",
       "      <td>Hay altísimas posibilidades de a ver echo bien...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>469251121354391553</td>\n",
       "      <td>Me tome un taxi con el primer tachero del mund...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>468435168693211136</td>\n",
       "      <td>Lindos trofeos trajo el rojo ayer!!! ☺ #Feliz ...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>469827996774187008</td>\n",
       "      <td>Llego el día. Campus 2014 GyE.. Muchas Gracias...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>464611519876321281</td>\n",
       "      <td>De esas veces qe solo puedo decir..... GRACIAS...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>465862724283801600</td>\n",
       "      <td>Muy lindo finde, muy jodido y lindo el festejo...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>469011283451604992</td>\n",
       "      <td>Estamos preparando #manualidades para éste fin...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>468504011377618944</td>\n",
       "      <td>Pues llegó el dia de acabar con las alarmas, d...</td>\n",
       "      <td>Alegria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0   465049714141200384  Buuenoos diiias ya estoy con mii pekeñaa!! Y c...   \n",
       "1   468241881428951041  Nuevos proyectos, nuevas metas, una nueva sema...   \n",
       "2   469580509895729153  Hay altísimas posibilidades de a ver echo bien...   \n",
       "3   469251121354391553  Me tome un taxi con el primer tachero del mund...   \n",
       "4   468435168693211136  Lindos trofeos trajo el rojo ayer!!! ☺ #Feliz ...   \n",
       "..                 ...                                                ...   \n",
       "56  469827996774187008  Llego el día. Campus 2014 GyE.. Muchas Gracias...   \n",
       "57  464611519876321281  De esas veces qe solo puedo decir..... GRACIAS...   \n",
       "58  465862724283801600  Muy lindo finde, muy jodido y lindo el festejo...   \n",
       "59  469011283451604992  Estamos preparando #manualidades para éste fin...   \n",
       "60  468504011377618944  Pues llegó el dia de acabar con las alarmas, d...   \n",
       "\n",
       "    emocion  \n",
       "0   Alegria  \n",
       "1   Alegria  \n",
       "2   Alegria  \n",
       "3   Alegria  \n",
       "4   Alegria  \n",
       "..      ...  \n",
       "56  Alegria  \n",
       "57  Alegria  \n",
       "58  Alegria  \n",
       "59  Alegria  \n",
       "60  Alegria  \n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'id':ids_list, 'text':text_list, 'emocion': emocion_list })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = pd.read_csv('../Data/SEL/SEL_full.txt', delimiter='\\t', encoding= 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emociones = list(sel['Categoría'].unique())\n",
    "emociones_dict ={}\n",
    "for emocion in emociones:\n",
    "    emociones_dict[emocion] = list(sel[sel['Categoría'] == emocion].sort_values(' PFA',  ascending=False).iloc[0:10]['Palabra'])\n",
    "    for palabra in emociones_dict[emocion]:\n",
    "        if not palabra.isascii():\n",
    "            emociones_dict[emocion].append(unidecode.unidecode(palabra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(emotion, words_list, number_tweets, start, end):\n",
    "    emotion_words = '(' +' OR '.join(words_list) + ')'\n",
    "    searched_tweets = [tweet for tweet in tweepy.Paginator(client.search_all_tweets, query = emotion_words + ' place_country:CO' ,start_time = start, end_time = end, \n",
    "                                max_results=500).flatten(limit=number_tweets)]\n",
    "    tweets_df = pd.DataFrame(searched_tweets, columns = ['text'])\n",
    "    tweets_df['emotion']= emotion\n",
    "    tweets_df['date']= start\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-02 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-03 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-04 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-05 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-06 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-07 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-08 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-09 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-10 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-11 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-12 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-13 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-14 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-15 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-16 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-17 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-18 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-19 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-20 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-21 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-22 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-23 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-24 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-25 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-26 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-27 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-28 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-29 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n",
      "2021-04-30 00:00:00\n",
      "Alegría\n",
      "Enojo\n",
      "Miedo\n",
      "Repulsión\n",
      "Sorpresa\n",
      "Tristeza\n"
     ]
    }
   ],
   "source": [
    "month = '04'\n",
    "start_date = datetime.strptime('2021-' + month, '%Y-%m')\n",
    "end_date = start_date + relativedelta(months=1)\n",
    "df_list = []\n",
    "while start_date < end_date:\n",
    "    print(start_date)\n",
    "    next_date = start_date + relativedelta(days=1)\n",
    "    start_date_standard = start_date.isoformat(\"T\") + \"Z\"\n",
    "    next_date_standard = next_date.isoformat(\"T\") + \"Z\"\n",
    "    for i in emociones_dict.keys():\n",
    "        print(i)\n",
    "        df_list.append(get_tweets(i, emociones_dict[i], 100, start_date_standard, next_date_standard ))\n",
    "        time.sleep(1)\n",
    "    start_date = next_date\n",
    "emociones_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emociones_df.to_csv('../Data/emociones_df.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emociones_df = pd.read_csv('../Data/emociones_df.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/juanjo/BETO/pytorch were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/juanjo/BETO/pytorch/\", do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained(\"/home/juanjo/BETO/pytorch\")\n",
    "e = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASK 0 : ['problemas', 'conflictos', 'asuntos', 'males', 'temas']\n",
      "MASK 1 : ['renunciar', 'actuar', 'intervenir', 'regresar', 'asumir']\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS] Para solucionar los [MASK] de Chile, el presidente debe [MASK] de inmediato. [SEP]\"\n",
    "masked_indxs = (4,11)\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "predictions = model(tokens_tensor)[0]\n",
    "\n",
    "for i,midx in enumerate(masked_indxs):\n",
    "    idxs = torch.argsort(predictions[0,midx], descending=True)\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens(idxs[:5])\n",
    "    print('MASK',i,':',predicted_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
